{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a25efed-2bcc-4e7d-badc-8ea441148426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76658bd5-c10d-4f38-8558-ff7d4ebeaa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbe6829d-62f8-4371-9ef1-306c7a7c7753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/sunil/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbf0eea1-ba33-42f5-b13d-352ca809e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    \"\"\"\n",
    "    Vocabulary class for handling word/token to index mapping\n",
    "    \"\"\"\n",
    "    def __init__(self, special_tokens=None):\n",
    "        if special_tokens is None:\n",
    "            self.special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "        else:\n",
    "            self.special_tokens = special_tokens\n",
    "        \n",
    "        # Initialize word to index and index to word mappings\n",
    "        self.word2idx = {token: idx for idx, token in enumerate(self.special_tokens)}\n",
    "        self.idx2word = {idx: token for idx, token in enumerate(self.special_tokens)}\n",
    "        self.word_count = {}  # For tracking word frequencies\n",
    "        \n",
    "        # Token indices\n",
    "        self.UNK_IDX = self.word2idx['<unk>']\n",
    "        self.PAD_IDX = self.word2idx['<pad>']\n",
    "        self.BOS_IDX = self.word2idx['<bos>']\n",
    "        self.EOS_IDX = self.word2idx['<eos>']\n",
    "        \n",
    "        # Current vocabulary size\n",
    "        self.n_words = len(self.special_tokens)\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        \"\"\"Add a word to the vocabulary\"\"\"\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.n_words\n",
    "            self.word_count[word] = 1\n",
    "            self.idx2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word_count[word] = self.word_count.get(word, 0) + 1\n",
    "        \n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    def add_words(self, words):\n",
    "        \"\"\"Add multiple words to the vocabulary\"\"\"\n",
    "        indices = []\n",
    "        for word in words:\n",
    "            indices.append(self.add_word(word))\n",
    "        return indices\n",
    "    \n",
    "    def prune_vocab(self, min_freq=2, max_size=None):\n",
    "        \"\"\"\n",
    "        Prune vocabulary to include only frequent words\n",
    "        \n",
    "        Args:\n",
    "            min_freq: Minimum frequency required for keeping a token\n",
    "            max_size: Maximum vocabulary size (including special tokens)\n",
    "        \"\"\"\n",
    "        # Sort words by frequency\n",
    "        sorted_words = sorted(self.word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Apply max_size limit if provided\n",
    "        if max_size is not None:\n",
    "            sorted_words = sorted_words[:max_size - len(self.special_tokens)]\n",
    "        \n",
    "        # Filter by frequency\n",
    "        filtered_words = [word for word, count in sorted_words if count >= min_freq]\n",
    "        \n",
    "        # Reset vocabulary\n",
    "        self.word2idx = {token: idx for idx, token in enumerate(self.special_tokens)}\n",
    "        self.idx2word = {idx: token for idx, token in enumerate(self.special_tokens)}\n",
    "        self.n_words = len(self.special_tokens)\n",
    "        \n",
    "        # Add filtered words\n",
    "        for word in filtered_words:\n",
    "            self.word2idx[word] = self.n_words\n",
    "            self.idx2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        \n",
    "        print(f\"Pruned vocabulary from {len(self.word_count)} to {self.n_words} tokens\")\n",
    "        \n",
    "        # Keep word_count intact for reference\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_words\n",
    "    \n",
    "    def to_json(self):\n",
    "        \"\"\"Serialize vocabulary to JSON format\"\"\"\n",
    "        return {\n",
    "            'word2idx': self.word2idx,\n",
    "            'idx2word': {str(idx): word for idx, word in self.idx2word.items()},\n",
    "            'word_count': self.word_count,\n",
    "            'n_words': self.n_words,\n",
    "            'special_tokens': self.special_tokens\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_data):\n",
    "        \"\"\"Create vocabulary from JSON data\"\"\"\n",
    "        vocab = cls(special_tokens=json_data['special_tokens'])\n",
    "        vocab.word2idx = json_data['word2idx']\n",
    "        vocab.idx2word = {int(idx): word for idx, word in json_data['idx2word'].items()}\n",
    "        vocab.word_count = json_data['word_count']\n",
    "        vocab.n_words = json_data['n_words']\n",
    "        \n",
    "        # Update special token indices\n",
    "        vocab.UNK_IDX = vocab.word2idx['<unk>']\n",
    "        vocab.PAD_IDX = vocab.word2idx['<pad>']\n",
    "        vocab.BOS_IDX = vocab.word2idx['<bos>']\n",
    "        vocab.EOS_IDX = vocab.word2idx['<eos>']\n",
    "        \n",
    "        return vocab\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\"Save vocabulary to file\"\"\"\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.to_json(), f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\"Load vocabulary from file\"\"\"\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return cls.from_json(json.load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86da594a-74a3-4f6e-b49d-0d2e0e32b78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer:\n",
    "    \"\"\"Simple tokenizer for text processing\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab, language='en'):\n",
    "        self.vocab = vocab\n",
    "        self.language = language\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenize text to list of tokens\"\"\"\n",
    "        # Simple word-level tokenization\n",
    "        # Can be replaced with more sophisticated tokenizers\n",
    "        tokens = text.lower().split()\n",
    "        return tokens\n",
    "    \n",
    "    def encode(self, text):\n",
    "        \"\"\"Convert text to list of token indices\"\"\"\n",
    "        tokens = self.tokenize(text)\n",
    "        indices = []\n",
    "        for token in tokens:\n",
    "            if token in self.vocab.word2idx:\n",
    "                indices.append(self.vocab.word2idx[token])\n",
    "            else:\n",
    "                indices.append(self.vocab.UNK_IDX)\n",
    "        return indices\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        \"\"\"Convert list of token indices to text\"\"\"\n",
    "        tokens = [self.vocab.idx2word.get(idx, '<unk>') for idx in indices]\n",
    "        return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8af576c-8ef7-42e0-8863-7f9795b6b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GermanEnglishDataset(Dataset):\n",
    "    \"\"\"Dataset for German-English translation pairs\"\"\"\n",
    "    \n",
    "    def __init__(self, german_texts, english_texts, src_tokenizer, tgt_tokenizer, \n",
    "                 max_len=100, is_train=True):\n",
    "        self.german_texts = german_texts\n",
    "        self.english_texts = english_texts\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Reference to vocabulary objects\n",
    "        self.src_vocab = src_tokenizer.vocab\n",
    "        self.tgt_vocab = tgt_tokenizer.vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.german_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        german_text = self.german_texts[idx]\n",
    "        english_text = self.english_texts[idx]\n",
    "        \n",
    "        # Tokenize and encode\n",
    "        german_tokens = self.src_tokenizer.encode(german_text)\n",
    "        english_tokens = self.tgt_tokenizer.encode(english_text)\n",
    "        \n",
    "        # Add BOS and EOS tokens to target (English)\n",
    "        english_tokens = [self.tgt_vocab.BOS_IDX] + english_tokens + [self.tgt_vocab.EOS_IDX]\n",
    "        \n",
    "        # Pad or truncate sequences\n",
    "        if len(german_tokens) < self.max_len:\n",
    "            german_tokens = german_tokens + [self.src_vocab.PAD_IDX] * (self.max_len - len(german_tokens))\n",
    "        else:\n",
    "            german_tokens = german_tokens[:self.max_len]\n",
    "            \n",
    "        if len(english_tokens) < self.max_len:\n",
    "            english_tokens = english_tokens + [self.tgt_vocab.PAD_IDX] * (self.max_len - len(english_tokens))\n",
    "        else:\n",
    "            english_tokens = english_tokens[:self.max_len]\n",
    "            \n",
    "        return {\n",
    "            'source': torch.tensor(german_tokens, dtype=torch.long),\n",
    "            'target': torch.tensor(english_tokens, dtype=torch.long),\n",
    "            'source_text': german_text,\n",
    "            'target_text': english_text\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a97c409-ff44-40ec-9703-211295537fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_parallel_text(src_file, tgt_file):\n",
    "    \"\"\"Load parallel text from files\"\"\"\n",
    "    with open(src_file, 'r', encoding='utf-8') as f:\n",
    "        src_texts = [line.strip() for line in f]\n",
    "    \n",
    "    with open(tgt_file, 'r', encoding='utf-8') as f:\n",
    "        tgt_texts = [line.strip() for line in f]\n",
    "    \n",
    "    assert len(src_texts) == len(tgt_texts), \"Source and target files have different number of lines\"\n",
    "    \n",
    "    return src_texts, tgt_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b15c632-8277-4692-9ff7-d83dc01974a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab_from_texts(texts, min_freq=2, max_size=None):\n",
    "    \"\"\"Build vocabulary from texts\"\"\"\n",
    "    vocab = Vocabulary()\n",
    "    \n",
    "    # Add all words to vocabulary\n",
    "    for text in texts:\n",
    "        words = text.lower().split()\n",
    "        vocab.add_words(words)\n",
    "    \n",
    "    # Prune vocabulary to include only frequent words\n",
    "    vocab.prune_vocab(min_freq=min_freq, max_size=max_size)\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71df5240-f414-4fb2-bd22-aa00402b9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(src_file, tgt_file, src_vocab=None, tgt_vocab=None, \n",
    "                min_freq=2, max_vocab_size=50000, max_len=100, batch_size=64,\n",
    "                train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, seed=42):\n",
    "    \"\"\"Prepare data for training, validation, and testing\"\"\"\n",
    "    # Load text\n",
    "    src_texts, tgt_texts = load_parallel_text(src_file, tgt_file)\n",
    "    print(f\"Loaded {len(src_texts)} parallel sentences\")\n",
    "    \n",
    "    # Build vocabularies if not provided\n",
    "    if src_vocab is None:\n",
    "        src_vocab = build_vocab_from_texts(src_texts, min_freq=min_freq, max_size=max_vocab_size)\n",
    "        print(f\"Built source vocabulary with {len(src_vocab)} tokens\")\n",
    "    \n",
    "    if tgt_vocab is None:\n",
    "        tgt_vocab = build_vocab_from_texts(tgt_texts, min_freq=min_freq, max_size=max_vocab_size)\n",
    "        print(f\"Built target vocabulary with {len(tgt_vocab)} tokens\")\n",
    "    \n",
    "    # Create tokenizers\n",
    "    src_tokenizer = SimpleTokenizer(src_vocab, language='de')\n",
    "    tgt_tokenizer = SimpleTokenizer(tgt_vocab, language='en')\n",
    "    \n",
    "    # Split data into train, validation, and test sets\n",
    "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1\"\n",
    "    \n",
    "    # Ensure reproducibility\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Shuffle indices\n",
    "    indices = list(range(len(src_texts)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    train_size = int(len(indices) * train_ratio)\n",
    "    val_size = int(len(indices) * val_ratio)\n",
    "    \n",
    "    # Split indices\n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = GermanEnglishDataset(\n",
    "        [src_texts[i] for i in train_indices],\n",
    "        [tgt_texts[i] for i in train_indices],\n",
    "        src_tokenizer, tgt_tokenizer, max_len=max_len, is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = GermanEnglishDataset(\n",
    "        [src_texts[i] for i in val_indices],\n",
    "        [tgt_texts[i] for i in val_indices],\n",
    "        src_tokenizer, tgt_tokenizer, max_len=max_len, is_train=False\n",
    "    )\n",
    "    \n",
    "    test_dataset = GermanEnglishDataset(\n",
    "        [src_texts[i] for i in test_indices],\n",
    "        [tgt_texts[i] for i in test_indices],\n",
    "        src_tokenizer, tgt_tokenizer, max_len=max_len, is_train=False\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    print(f\"Split data into {len(train_dataset)} train, {len(val_dataset)} validation, and {len(test_dataset)} test samples\")\n",
    "    \n",
    "    return {\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'val_dataloader': val_dataloader,\n",
    "        'test_dataloader': test_dataloader,\n",
    "        'src_vocab': src_vocab,\n",
    "        'tgt_vocab': tgt_vocab,\n",
    "        'src_tokenizer': src_tokenizer,\n",
    "        'tgt_tokenizer': tgt_tokenizer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ed8f48f-7b28-4884-a79e-af660634e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Adds positional encoding to the token embeddings to introduce a notion of word order.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Create a tensor of shape (max_len, d_model)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        # Create a tensor of shape (max_len, 1)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # Calculate the division term\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        # Apply sine to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "        # Apply cosine to odd indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Add batch dimension\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        # Register buffer (not a parameter, but should be saved and moved to device)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df0d1d55-5216-4588-a699-1a29ce3c4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Attention module as described in \"Attention is All You Need\"\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        # Linear projections for Q, K, V\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Dropout for attention\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            q: Query tensor, shape [batch_size, seq_len_q, d_model]\n",
    "            k: Key tensor, shape [batch_size, seq_len_k, d_model]\n",
    "            v: Value tensor, shape [batch_size, seq_len_v, d_model]\n",
    "            mask: Optional mask tensor, shape [batch_size, seq_len_q, seq_len_k]\n",
    "        \"\"\"\n",
    "        batch_size = q.size(0)\n",
    "        \n",
    "        # Apply linear projections and reshape to [batch_size, num_heads, seq_len, d_k]\n",
    "        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            # Add head dimension to mask\n",
    "            if mask.dim() == 3:  # [batch_size, seq_len_q, seq_len_k]\n",
    "                mask = mask.unsqueeze(1)  # [batch_size, 1, seq_len_q, seq_len_k]\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Apply attention weights to values\n",
    "        output = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # Reshape back to [batch_size, seq_len, d_model]\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        # Apply output projection\n",
    "        return self.output(output), attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92c8235-2dea-48a4-b151-04965c4d3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedforward(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise Feed-Forward Network as described in \"Attention is All You Need\"\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedforward, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor, shape [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        x = self.dropout(F.relu(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b55175d-7eae-4aa9-9524-bc01ee90baa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder layer in a Transformer model.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff, dropout)\n",
    "        \n",
    "        # Layer normalization layers\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout for residual connections\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor, shape [batch_size, seq_len, d_model]\n",
    "            mask: Optional mask tensor, shape [batch_size, seq_len, seq_len]\n",
    "        \"\"\"\n",
    "        # Self-attention with residual connection and layer normalization\n",
    "        attn_output, _ = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward with residual connection and layer normalization\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e49e9dc1-49c7-46ae-9040-382bd7fa65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder layer in a Transformer model.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedforward(d_model, d_ff, dropout)\n",
    "        \n",
    "        # Layer normalization layers\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout for residual connections\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Target sequence, shape [batch_size, tgt_seq_len, d_model]\n",
    "            enc_output: Encoder output, shape [batch_size, src_seq_len, d_model]\n",
    "            src_mask: Source sequence mask, shape [batch_size, 1, src_seq_len]\n",
    "            tgt_mask: Target sequence mask, shape [batch_size, tgt_seq_len, tgt_seq_len]\n",
    "        \"\"\"\n",
    "        # Self-attention with residual connection and layer normalization\n",
    "        self_attn_output, _ = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(self_attn_output))\n",
    "        \n",
    "        # Cross-attention with encoder output\n",
    "        cross_attn_output, _ = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(cross_attn_output))\n",
    "        \n",
    "        # Feed-forward with residual connection and layer normalization\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d669574f-151a-4218-aa90-a8757951ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Transformer model for Neural Machine Translation.\n",
    "    \"\"\"\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8,\n",
    "                 num_encoder_layers=6, num_decoder_layers=6, d_ff=2048, max_len=100,\n",
    "                 dropout=0.1, pad_idx=1):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, d_model, padding_idx=pad_idx)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model, padding_idx=pad_idx)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len, dropout)\n",
    "        \n",
    "        # Encoder and decoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_decoder_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_projection = nn.Linear(d_model, tgt_vocab_size)\n",
    "        \n",
    "        # Initialize parameters\n",
    "        self._init_parameters()\n",
    "        \n",
    "    def _init_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize model parameters.\n",
    "        \"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                \n",
    "    def _create_src_mask(self, src):\n",
    "        \"\"\"\n",
    "        Create padding mask for source sequence.\n",
    "        \"\"\"\n",
    "        # src: [batch_size, src_seq_len]\n",
    "        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # src_mask: [batch_size, 1, 1, src_seq_len]\n",
    "        return src_mask\n",
    "    \n",
    "    def _create_tgt_mask(self, tgt):\n",
    "        \"\"\"\n",
    "        Create both padding and look-ahead mask for target sequence.\n",
    "        \"\"\"\n",
    "        # tgt: [batch_size, tgt_seq_len]\n",
    "        batch_size, tgt_seq_len = tgt.size()\n",
    "        \n",
    "        # Padding mask\n",
    "        padding_mask = (tgt != self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # padding_mask: [batch_size, 1, 1, tgt_seq_len]\n",
    "        \n",
    "        # Look-ahead mask\n",
    "        look_ahead_mask = torch.ones(tgt_seq_len, tgt_seq_len, device=device).triu(diagonal=1).eq(0)\n",
    "        # look_ahead_mask: [tgt_seq_len, tgt_seq_len]\n",
    "        \n",
    "        # Combine padding and look-ahead masks\n",
    "        combined_mask = padding_mask & look_ahead_mask\n",
    "        # combined_mask: [batch_size, 1, tgt_seq_len, tgt_seq_len]\n",
    "        \n",
    "        return combined_mask\n",
    "    \n",
    "    def encode(self, src, src_mask=None):\n",
    "        \"\"\"\n",
    "        Encode source sequence.\n",
    "        \"\"\"\n",
    "        # src: [batch_size, src_seq_len]\n",
    "        if src_mask is None:\n",
    "            src_mask = self._create_src_mask(src)\n",
    "        \n",
    "        # Apply embedding and positional encoding\n",
    "        src_embedded = self.src_embedding(src) * math.sqrt(self.d_model)\n",
    "        src_embedded = self.positional_encoding(src_embedded)\n",
    "        \n",
    "        # Apply encoder layers\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "            \n",
    "        return enc_output, src_mask\n",
    "    \n",
    "    def decode(self, tgt, enc_output, src_mask=None, tgt_mask=None):\n",
    "        \"\"\"\n",
    "        Decode target sequence given encoded source.\n",
    "        \"\"\"\n",
    "        # tgt: [batch_size, tgt_seq_len]\n",
    "        if tgt_mask is None:\n",
    "            tgt_mask = self._create_tgt_mask(tgt)\n",
    "            \n",
    "        # Apply embedding and positional encoding\n",
    "        tgt_embedded = self.tgt_embedding(tgt) * math.sqrt(self.d_model)\n",
    "        tgt_embedded = self.positional_encoding(tgt_embedded)\n",
    "        \n",
    "        # Apply decoder layers\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "            \n",
    "        # Apply output projection\n",
    "        output = self.output_projection(dec_output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        Forward pass of the Transformer model.\n",
    "        \"\"\"\n",
    "        # src: [batch_size, src_seq_len]\n",
    "        # tgt: [batch_size, tgt_seq_len]\n",
    "        \n",
    "        # Create masks\n",
    "        src_mask = self._create_src_mask(src)\n",
    "        tgt_mask = self._create_tgt_mask(tgt)\n",
    "        \n",
    "        # Encode source\n",
    "        enc_output, src_mask = self.encode(src, src_mask)\n",
    "        \n",
    "        # Decode target\n",
    "        output = self.decode(tgt, enc_output, src_mask, tgt_mask)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8f978d0-f2fb-4131-a06a-c01df24eb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(model, src, tgt_vocab, max_len=100, beam_size=5, device=device):\n",
    "    \"\"\"\n",
    "    Beam Search for inference.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Transformer model\n",
    "        src: Source sequence tensor, shape [1, src_seq_len]\n",
    "        tgt_vocab: Target vocabulary\n",
    "        max_len: Maximum length of generated sequence\n",
    "        beam_size: Beam size\n",
    "        device: Device to run inference on\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Constants\n",
    "    batch_size = src.size(0)\n",
    "    PAD_IDX = tgt_vocab.PAD_IDX\n",
    "    BOS_IDX = tgt_vocab.BOS_IDX\n",
    "    EOS_IDX = tgt_vocab.EOS_IDX\n",
    "    \n",
    "    # Encode source\n",
    "    src_mask = model._create_src_mask(src)\n",
    "    enc_output, src_mask = model.encode(src, src_mask)\n",
    "    \n",
    "    # Initialize beams with <BOS> token\n",
    "    beams = torch.full((batch_size * beam_size, 1), BOS_IDX, dtype=torch.long, device=device)\n",
    "    beam_scores = torch.zeros(batch_size, beam_size, device=device)\n",
    "    \n",
    "    # Track completed sequences\n",
    "    completed_seqs = [[] for _ in range(batch_size)]\n",
    "    completed_scores = [[] for _ in range(batch_size)]\n",
    "    \n",
    "    # Repeat encoder outputs for beam size\n",
    "    enc_output = enc_output.repeat_interleave(beam_size, dim=0)\n",
    "    src_mask = src_mask.repeat_interleave(beam_size, dim=0)\n",
    "    \n",
    "    # Generate tokens step by step\n",
    "    for step in range(max_len - 1):\n",
    "        tgt = beams\n",
    "        \n",
    "        # Get model predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model.decode(tgt, enc_output, src_mask)\n",
    "            \n",
    "        # Get predictions for next token\n",
    "        next_token_logits = logits[:, -1, :]  # [batch_size*beam_size, vocab_size]\n",
    "        next_token_scores = F.log_softmax(next_token_logits, dim=-1)  # [batch_size*beam_size, vocab_size]\n",
    "        \n",
    "        # Reshape for beam search\n",
    "        next_token_scores = next_token_scores.view(batch_size, beam_size, -1)  # [batch_size, beam_size, vocab_size]\n",
    "        vocab_size = next_token_scores.size(-1)\n",
    "        \n",
    "        # Calculate cumulative scores\n",
    "        beam_scores_expanded = beam_scores.unsqueeze(-1).expand(-1, -1, vocab_size)  # [batch_size, beam_size, vocab_size]\n",
    "        next_scores = beam_scores_expanded + next_token_scores  # [batch_size, beam_size, vocab_size]\n",
    "        \n",
    "        # Flatten for top-k selection\n",
    "        next_scores_flat = next_scores.view(batch_size, -1)  # [batch_size, beam_size*vocab_size]\n",
    "        \n",
    "        # Select top-k scores\n",
    "        topk_scores, topk_indices = next_scores_flat.topk(beam_size, dim=1, largest=True, sorted=True)\n",
    "        \n",
    "        # Convert indices to beam and token indices\n",
    "        beam_indices = topk_indices // vocab_size  # [batch_size, beam_size]\n",
    "        token_indices = topk_indices % vocab_size  # [batch_size, beam_size]\n",
    "        \n",
    "        # Update beam scores\n",
    "        beam_scores = topk_scores  # [batch_size, beam_size]\n",
    "        \n",
    "        # Prepare for next iteration\n",
    "        new_beams = []\n",
    "        for batch_idx in range(batch_size):\n",
    "            for beam_idx in range(beam_size):\n",
    "                # Get selected beam and token\n",
    "                prev_beam = beam_indices[batch_idx, beam_idx]\n",
    "                token = token_indices[batch_idx, beam_idx]\n",
    "                score = beam_scores[batch_idx, beam_idx]\n",
    "                \n",
    "                # Get previous sequence\n",
    "                prev_seq = beams[batch_idx * beam_size + prev_beam]\n",
    "                \n",
    "                # Check if sequence is completed\n",
    "                if token.item() == EOS_IDX:\n",
    "                    completed_seqs[batch_idx].append(prev_seq.tolist())\n",
    "                    completed_scores[batch_idx].append(score.item())\n",
    "                    # Add a pad token to maintain beam size\n",
    "                    new_seq = torch.cat([prev_seq, torch.tensor([PAD_IDX], device=device)])\n",
    "                else:\n",
    "                    # Add token to sequence\n",
    "                    new_seq = torch.cat([prev_seq, token.unsqueeze(0)])\n",
    "                \n",
    "                new_beams.append(new_seq)\n",
    "        \n",
    "        # Stack beams for next iteration\n",
    "        beams = torch.stack(new_beams).view(batch_size * beam_size, -1)\n",
    "        \n",
    "        # Check if all beams have completed\n",
    "        if all(len(seqs) >= beam_size for seqs in completed_seqs):\n",
    "            break\n",
    "    \n",
    "    # Select best sequences from each batch\n",
    "    results = []\n",
    "    for batch_idx in range(batch_size):\n",
    "        # Add any remaining beams to completed_seqs if needed\n",
    "        if len(completed_seqs[batch_idx]) < beam_size:\n",
    "            for beam_idx in range(beam_size):\n",
    "                seq = beams[batch_idx * beam_size + beam_idx].tolist()\n",
    "                if EOS_IDX in seq:\n",
    "                    # Truncate at EOS\n",
    "                    seq = seq[:seq.index(EOS_IDX) + 1]\n",
    "                else:\n",
    "                    # Add EOS if not present\n",
    "                    seq = seq + [EOS_IDX]\n",
    "                \n",
    "                completed_seqs[batch_idx].append(seq)\n",
    "                completed_scores[batch_idx].append(beam_scores[batch_idx, beam_idx].item())\n",
    "        \n",
    "        # Get best sequence based on score\n",
    "        best_idx = max(range(len(completed_scores[batch_idx])), \n",
    "                      key=lambda i: completed_scores[batch_idx][i])\n",
    "        best_seq = completed_seqs[batch_idx][best_idx]\n",
    "        \n",
    "        # Remove special tokens (keeping only the needed ones)\n",
    "        if BOS_IDX in best_seq:\n",
    "            best_seq = best_seq[1:]  # Remove BOS\n",
    "        if EOS_IDX in best_seq:\n",
    "            best_seq = best_seq[:best_seq.index(EOS_IDX)]  # Remove everything after EOS\n",
    "            \n",
    "        results.append(best_seq)\n",
    "    \n",
    "    # Convert token indices to words\n",
    "    translated_sentences = []\n",
    "    for seq in results:\n",
    "        words = [tgt_vocab.idx2word.get(idx, '<unk>') for idx in seq]\n",
    "        translated_sentences.append(\" \".join(words))\n",
    "    \n",
    "    return translated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72e60453-ea01-498a-b042-379fdf74fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Count the number of trainable parameters in the model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ea727e-e0ad-454a-a4dd-8b28e2028fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    \"\"\"Initialize weights for the model\"\"\"\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "782b43f1-feb6-4056-b2f8-970f736ba7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, clip=1.0):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \n",
    "    Args:\n",
    "        model: Transformer model\n",
    "        dataloader: Training data loader\n",
    "        optimizer: Optimizer\n",
    "        criterion: Loss function\n",
    "        clip: Gradient clipping value\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Get source and target sequences\n",
    "        src = batch['source'].to(device)\n",
    "        tgt = batch['target'].to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass - teacher forcing\n",
    "        # Input: all but the last token\n",
    "        # Target: all but the first token (<sos>)\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        \n",
    "        # Reshape output and target for loss computation\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, tgt)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=epoch_loss / (progress_bar.n + 1))\n",
    "    \n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f9a97f5-5380-444c-962e-94765acf7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    \"\"\"\n",
    "    Evaluate the model on validation or test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Transformer model\n",
    "        dataloader: Validation/Test data loader\n",
    "        criterion: Loss function\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            # Get source and target sequences\n",
    "            src = batch['source'].to(device)\n",
    "            tgt = batch['target'].to(device)\n",
    "            \n",
    "            # Forward pass - teacher forcing\n",
    "            output = model(src, tgt[:, :-1])\n",
    "            \n",
    "            # Reshape output and target for loss computation\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(output, tgt)\n",
    "            \n",
    "            # Update loss\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79bf1a46-8717-4fe5-809f-655fefb920ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(model, src_tokenizer, tgt_vocab, src_text, max_len=100, beam_size=5):\n",
    "    \"\"\"\n",
    "    Translate a source text from German to English.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Transformer model\n",
    "        src_tokenizer: Source tokenizer (German)\n",
    "        tgt_vocab: Target vocabulary (English)\n",
    "        src_text: Source text in German\n",
    "        max_len: Maximum length of generated sequence\n",
    "        beam_size: Beam size for beam search\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize source text\n",
    "    tokens = src_tokenizer.encode(src_text)\n",
    "    \n",
    "    # Add batch dimension\n",
    "    src = torch.tensor([tokens], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Perform beam search\n",
    "    translated = beam_search(model, src, tgt_vocab, max_len, beam_size, device)\n",
    "    \n",
    "    return translated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a60816b7-6604-446f-b553-773edd5135ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(model, test_dataloader, src_tokenizer, tgt_vocab, max_len=100, beam_size=5):\n",
    "    \"\"\"\n",
    "    Calculate BLEU score on test data.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Transformer model\n",
    "        test_dataloader: Test data loader\n",
    "        src_tokenizer: Source tokenizer (German)\n",
    "        tgt_vocab: Target vocabulary (English)\n",
    "        max_len: Maximum length of generated sequence\n",
    "        beam_size: Beam size for beam search\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Calculating BLEU\", leave=False):\n",
    "            # Get source and reference texts\n",
    "            src_texts = batch['source_text']\n",
    "            trg_texts = batch['target_text']\n",
    "            \n",
    "            # Translate each source text\n",
    "            for src_text, ref_text in zip(src_texts, trg_texts):\n",
    "                # Get reference tokens (removing special tokens)\n",
    "                ref_tokens = nltk.word_tokenize(ref_text.lower())\n",
    "                references.append([ref_tokens])\n",
    "                \n",
    "                # Translate source text\n",
    "                translated = translate(model, src_tokenizer, tgt_vocab, src_text, max_len, beam_size)\n",
    "                \n",
    "                # Tokenize translated text\n",
    "                hyp_tokens = nltk.word_tokenize(translated.lower())\n",
    "                hypotheses.append(hyp_tokens)\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    bleu_score = corpus_bleu(references, hypotheses, smoothing_function=smoothing)\n",
    "    \n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "556b72b5-fbe5-416e-a79d-b82852aa6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataloader, valid_dataloader, src_vocab_size, tgt_vocab_size, \n",
    "                d_model=512, num_heads=8, num_encoder_layers=6, num_decoder_layers=6, \n",
    "                d_ff=2048, max_len=100, dropout=0.1, lr=0.0005, n_epochs=10, \n",
    "                clip=1.0, warmup_steps=4000, pad_idx=1):\n",
    "    \"\"\"\n",
    "    Train the Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        train_dataloader: Training data loader\n",
    "        valid_dataloader: Validation data loader\n",
    "        src_vocab_size: Size of source vocabulary\n",
    "        tgt_vocab_size: Size of target vocabulary\n",
    "        d_model: Dimension of model\n",
    "        num_heads: Number of attention heads\n",
    "        num_encoder_layers: Number of encoder layers\n",
    "        num_decoder_layers: Number of decoder layers\n",
    "        d_ff: Dimension of feed-forward network\n",
    "        max_len: Maximum sequence length\n",
    "        dropout: Dropout rate\n",
    "        lr: Learning rate\n",
    "        n_epochs: Number of training epochs\n",
    "        clip: Gradient clipping value\n",
    "        warmup_steps: Number of warmup steps for learning rate scheduler\n",
    "        pad_idx: Padding index\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    model = Transformer(\n",
    "        src_vocab_size=src_vocab_size,\n",
    "        tgt_vocab_size=tgt_vocab_size,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        num_decoder_layers=num_decoder_layers,\n",
    "        d_ff=d_ff,\n",
    "        max_len=max_len,\n",
    "        dropout=dropout,\n",
    "        pad_idx=pad_idx\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"The model has {count_parameters(model):,} trainable parameters\")\n",
    "    \n",
    "    # Initialize weights\n",
    "    model.apply(initialize_weights)\n",
    "    \n",
    "    # Define optimizer and learning rate scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "    \n",
    "    # Learning rate scheduler with warmup\n",
    "    def lr_lambda(step):\n",
    "        # Linear warmup for warmup_steps steps\n",
    "        if step < warmup_steps:\n",
    "            return float(step) / float(max(1, warmup_steps))\n",
    "        # Decrease learning rate after warmup\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * (step - warmup_steps) / n_epochs)))\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "    # Define loss function (ignore padding index)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "    \n",
    "    # Track best validation loss\n",
    "    best_valid_loss = float('inf')\n",
    "    \n",
    "    # Training and validation losses history\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        \n",
    "        # Train model for one epoch\n",
    "        start_time = time.time()\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer, criterion, clip)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        valid_loss = evaluate(model, valid_dataloader, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save model if validation loss improves\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            print(\"* New best model saved *\")\n",
    "        \n",
    "        # Print epoch stats\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "        print(f\"Time: {epoch_mins}m {epoch_secs:.2f}s | Train Loss: {train_loss:.4f} | Val Loss: {valid_loss:.4f}\")\n",
    "    \n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(valid_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('training_loss.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return model, train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e2cf8d5-7cab-4652-8760-4da276fa73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_dataset():\n",
    "    \"\"\"\n",
    "    Create a small sample dataset for demonstration purposes.\n",
    "    \"\"\"\n",
    "    de_samples = [\n",
    "        \"Ich gehe zur Schule.\",\n",
    "        \"Obwohl es regnete, ging sie ohne Regenschirm spazieren.\",\n",
    "        \"Der Klimawandel ist ein globales Problem.\",\n",
    "        \"Berlin ist die Hauptstadt von Deutschland.\",\n",
    "        \"Das Buch, das auf dem Tisch liegt, gehrt meinem Bruder.\",\n",
    "        \"Sie arbeitet als rztin in einem Krankenhaus.\",\n",
    "        \"Er hat gestern seinen Geburtstag gefeiert.\",\n",
    "        \"Wir sollten mehr Obst und Gemse essen.\",\n",
    "        \"Die Kinder spielen im Park.\",\n",
    "        \"Ich lerne seit zwei Jahren Deutsch.\"\n",
    "    ]\n",
    "    \n",
    "    en_samples = [\n",
    "        \"I am going to school.\",\n",
    "        \"Although it was raining, she went for a walk without an umbrella.\",\n",
    "        \"Climate change is a global problem.\",\n",
    "        \"Berlin is the capital of Germany.\",\n",
    "        \"The book that is on the table belongs to my brother.\",\n",
    "        \"She works as a doctor in a hospital.\",\n",
    "        \"He celebrated his birthday yesterday.\",\n",
    "        \"We should eat more fruit and vegetables.\",\n",
    "        \"The children are playing in the park.\",\n",
    "        \"I have been learning German for two years.\"\n",
    "    ]\n",
    "    \n",
    "    # Save samples to files\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    with open('data/sample.de', 'w', encoding='utf-8') as f:\n",
    "        for text in de_samples:\n",
    "            f.write(f\"{text}\\n\")\n",
    "    \n",
    "    with open('data/sample.en', 'w', encoding='utf-8') as f:\n",
    "        for text in en_samples:\n",
    "            f.write(f\"{text}\\n\")\n",
    "    \n",
    "    print(\"Created sample dataset in data/sample.de and data/sample.en\")\n",
    "    \n",
    "    return 'data/sample.de', 'data/sample.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87987cda-dbd8-4c49-a813-d6be36807ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = 'data/train.de'\n",
    "tgt_file = 'data/train.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a890890-ff4f-4a93-8fc7-0425e1500883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data not found. Creating sample dataset.\n",
      "Created sample dataset in data/sample.de and data/sample.en\n"
     ]
    }
   ],
   "source": [
    "if not (os.path.exists(src_file) and os.path.exists(tgt_file)):\n",
    "    print(\"Training data not found. Creating sample dataset.\")\n",
    "    src_file, tgt_file = create_sample_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7e01b56-25a9-4619-870c-889fcc47dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "max_len = 100\n",
    "min_freq = 2\n",
    "max_vocab_size = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "155e1329-7da7-46c3-8fbc-09ec5646d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 parallel sentences\n",
      "Pruned vocabulary from 60 to 9 tokens\n",
      "Built source vocabulary with 9 tokens\n",
      "Pruned vocabulary from 61 to 12 tokens\n",
      "Built target vocabulary with 12 tokens\n",
      "Split data into 8 train, 1 validation, and 1 test samples\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data(\n",
    "    src_file=src_file, \n",
    "    tgt_file=tgt_file,\n",
    "    min_freq=min_freq,\n",
    "    max_vocab_size=max_vocab_size,\n",
    "    max_len=max_len,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbe2b3c7-658e-4479-89a1-1cdff4e208c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data['train_dataloader']\n",
    "val_dataloader = data['val_dataloader']\n",
    "test_dataloader = data['test_dataloader']\n",
    "src_vocab = data['src_vocab']\n",
    "tgt_vocab = data['tgt_vocab']\n",
    "src_tokenizer = data['src_tokenizer']\n",
    "tgt_tokenizer = data['tgt_tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5a2df4b-0d8a-4a40-88fb-bcc20453d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "src_vocab.save('models/vocab.de.json')\n",
    "tgt_vocab.save('models/vocab.en.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2560f6a-4f0e-46c7-a716-0c33a720e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "d_ff = 2048\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4151a81b-dd42-443f-8188-deb4b4918295",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0005\n",
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "warmup_steps = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0846b2b8-2c10-45c3-bf97-0b55c3c97848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 44,155,404 trainable parameters\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.38s | Train Loss: 2.7949 | Val Loss: 3.1422\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.38s | Train Loss: 2.7894 | Val Loss: 3.1140\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.36s | Train Loss: 2.8140 | Val Loss: 3.0584\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.36s | Train Loss: 2.6038 | Val Loss: 2.9771\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.36s | Train Loss: 2.6476 | Val Loss: 2.8729\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.36s | Train Loss: 2.5282 | Val Loss: 2.7479\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.37s | Train Loss: 2.3646 | Val Loss: 2.6087\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.37s | Train Loss: 2.5238 | Val Loss: 2.4605\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.38s | Train Loss: 2.2681 | Val Loss: 2.3120\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* New best model saved *\n",
      "Time: 0.0m 0.36s | Train Loss: 2.1335 | Val Loss: 2.1738\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, valid_losses = train_model(\n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        len(src_vocab), \n",
    "        len(tgt_vocab),\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        d_ff,\n",
    "        max_len,\n",
    "        dropout,\n",
    "        lr,\n",
    "        n_epochs,\n",
    "        clip,\n",
    "        warmup_steps,\n",
    "        pad_idx=src_vocab.PAD_IDX\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42ba55ca-b4a4-4c4e-a7ce-0d551a4431fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/final_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5ed1c81-ef78-436d-ad1d-883e80b64f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU score on test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(\"Calculating BLEU score on test data...\")\n",
    "bleu_score = calculate_bleu(model, test_dataloader, src_tokenizer, tgt_vocab)\n",
    "print(f\"BLEU score: {bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8702d9e6-3c3c-4958-8efb-b4dde5d1a856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example translations:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExample translations:\")\n",
    "test_sentences = [\n",
    "    \"Ich gehe zur Schule.\",\n",
    "    \"Obwohl es regnete, ging sie ohne Regenschirm spazieren.\",\n",
    "    \"Der Klimawandel ist ein globales Problem.\",\n",
    "    \"Berlin ist die Hauptstadt von Deutschland.\",\n",
    "    \"Das Buch, das auf dem Tisch liegt, gehrt meinem Bruder.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "373e9dc9-3319-477c-bb33-e29273d834c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE: Ich gehe zur Schule.\n",
      "EN: <unk> <unk> <unk> <unk> she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she\n",
      "--------------------------------------------------\n",
      "DE: Obwohl es regnete, ging sie ohne Regenschirm spazieren.\n",
      "EN: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "--------------------------------------------------\n",
      "DE: Der Klimawandel ist ein globales Problem.\n",
      "EN: <unk> <unk> <unk> <unk> <unk> <unk> she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she\n",
      "--------------------------------------------------\n",
      "DE: Berlin ist die Hauptstadt von Deutschland.\n",
      "EN: she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she she\n",
      "--------------------------------------------------\n",
      "DE: Das Buch, das auf dem Tisch liegt, gehrt meinem Bruder.\n",
      "EN: \n",
      "--------------------------------------------------\n",
      "================================================================================\n",
      "Neural Machine Translation model training and evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "for sent in test_sentences:\n",
    "    translated = translate(model, src_tokenizer, tgt_vocab, sent)\n",
    "    print(f\"DE: {sent}\")\n",
    "    print(f\"EN: {translated}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Neural Machine Translation model training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62622d94-ff71-4cf2-8ca3-25739787d9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
